@inproceedings{Swan2008,
abstract = {This paper examines an under explored area of digital photography, namely photo display. Using examples from a study undertaken with six families, we examine photo displays on mantelpieces, sideboards, and hallway walls, and in homeoffices. Using the ...},
author = {Swan, Laurel and Taylor, Alex S},
booktitle = {Proc of DIS},
year={2008},
pages = {261--270},
title = {{Photo displays in the home}}
}

@article{lindley:2009,
author={Sian Lindley and Abigail Durrant and David Kirk and Alex S. Taylor},
title={Collocated social practices surrounding photos},
journal={Int J Hum-comput St},
Issue={Feb},
year={2009}

@inproceedings{mynatt:2001,
author={E.D. Mynatt and J. Rowan and S. Craighill and A. Jacobs},
title={Digital Family Portraits: Providing Peace of Mind for Extended Family Members},
booktitle={Proc. of CHI},
year={2001}
}

@inproceedings{gerling:2013,
 author = {Gerling, Kathrin M. and Kalyn, Michael R. and Mandryk, Regan L.},
 title = {KINECTwheels: Wheelchair-accessible Motion-based Game Interaction},
 booktitle = {Extended Abstracts of CHI},
 year = {2013},
 pages = {3055--3058},
 keywords = {accessibility, design, entertainment, games},
} 

@article{lindley:2012,
 author = {Lindley, Si\&\#x00e2;n E.},
 title = {Shades of lightweight: supporting cross-generational communication through home messaging},
 journal = {Univers. Access Inf. Soc.},
 issue_date = {March 2012},
 volume = {11},
 number = {1},
 year = {2012},
 pages = {31--43},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg}
} 

@inproceedings{arreola:2014,
 author = {Arreola, Ingrid and Morris, Zan and Francisco, Matthew and Connelly, Kay and Caine, Kelly and White, Ginger},
 title = {From Checking on to Checking in: Designing for Low Socio-economic Status Older Adults},
 booktitle = {Proc of CHI},
 pages = {1933--1936},
 year={2014}
} 

@inproceedings{sundar:2011,
 author = {Sundar, S. Shyam and Oeldorf-Hirsch, Anne and Nussbaum, Jon and Behr, Richard},
 title = {Retirees on Facebook: can online social networking enhance their health and wellness?},
 booktitle = {Proc of CHI},
 year = {2011},
 pages = {2287-2292}
} 

@article{pew:2014,
year={2014},
author={A. Smith},
title={Older Adults and Technology Use:  Adoption is increasing but many seniors remain isolated from digital life},
journal={Pew Research Center}
}

@inproceedings{Corsten2013,
abstract = {Dedicated input devices are frequently used for system control. We present Instant User Interfaces, an interaction paradigm that loosens this dependency and allows operating a system even when its dedicated controller is unavailable. We implemented a reliable, marker-free object tracking system that enables users to assign semantic meaning to different poses or to touches in different areas. With this system, users can repurpose everyday objects and program them in an ad-hoc manner, using a GUI or by demonstration, as input devices. Users tested and ranked these methods alongside a Wizard-of-Oz speech interface. The testers did not show a clear preference as a group, but had individual preferences.},
author = {Corsten, Christian and Avellino, Ignacio and M\"{o}llers, Max and Borchers, Jan},
booktitle = {Proc of ITS},
doi = {10.1145/2512349.2512799},
pages = {71--80},
title = {{Instant User Interfaces: Repurposing Everyday Objects as Input Devices}},
year = {2013}
}
@article{Pew2012,
author = {Zickuhr, Katheryn and Madden, Mary},
howpublished = {http://pewinternet.org/Reports/2012/Older-adults-and-internet-use.aspx},
title = {{Older Adults and Internet Use}},
journal={Pew Research Center},
year = {2012}
}
@inproceedings{Lightbeam2012,
 author = {Huber, Jochen and Steimle, J\"{u}rgen and Liao, Chunyuan and Liu, Qiong and M\"{u}hlh\"{a}user, Max},
 title = {LightBeam: Interacting with Augmented Real-world Objects in Pico Projections},
 booktitle = {Proceedings of the 11th International Conference on Mobile and Ubiquitous Multimedia},
 series = {MUM '12},
 year = {2012},
 isbn = {978-1-4503-1815-0},
 location = {Ulm, Germany},
 pages = {16:1--16:10},
 articleno = {16},
 numpages = {10},
 url = {http://doi.acm.org.turing.library.northwestern.edu/10.1145/2406367.2406388},
 doi = {10.1145/2406367.2406388},
 acmid = {2406388},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {augmented reality, embodied interaction, handheld projectors, mixed reality, mobile devices, pico projectors}
} 
@article{WilsonLightspace2010,
abstract = {Instrumented with multiple depth cameras and projectors, LightSpace is a small room installation designed to explore a variety of interactions and computational strategies related to interactive displays and the space that they inhabit. LightSpace cameras and projectors are calibrated to 3D real world coordinates, allowing for projection of graphics correctly onto any surface visible by both camera and projector. Selective projection of the depth camera data enables emulation of interactive displays on un-instrumented surfaces (such as a standard table or office desk), as well as facilitates mid-air interactions between and around these displays. For example, after performing multi-touch interactions on a virtual object on the tabletop, the user may transfer the object to another display by simultaneously touching the object and the destination display. Or the user may “pick up” the object by sweeping it into their hand, see it sitting in their hand as they walk over to an interactive wall display, and “drop” the object onto the wall by touching it with their other hand. We detail the interactions and algorithms unique to LightSpace, discuss some initial observations of use and suggest future directions.},
author = {Wilson, Andrew D. and Benko, Hrvoje},
doi = {10.1145/1866029.1866073},
isbn = {9781450302715},
journal = {Proceedings of the 23nd annual ACM symposium on User interface software and technology - UIST '10},
keywords = {augmented reality,cameras,depth,interactive spaces,surface computing,ubiquitous computing},
pages = {273},
title = {{Combining multiple depth cameras and projectors for interactions on, above and between surfaces}},
url = {http://portal.acm.org/citation.cfm?doid=1866029.1866073$\backslash$nhttp://research.microsoft.com/en-us/um/people/awilson/publications/wilsonuist2010/wilson uist 2010 lightspace.pdf},
year = {2010}
}
@inproceedings{Wilson2010,
abstract = {We explore the application of depth-sensing cameras to detect touch on a tabletop. Limits of depth estimate resolution and line of sight requirements dictate that the determination of the moment of touch will not be as precise as that of more direct sensing techniques such as capacitive touch screens. However, using a depth-sensing camera to detect touch has significant advantages: first, the interactive surface need not be instrumented. Secondly, this approach allows touch sensing on non-flat surfaces. Finally, information about the shape of the users and their arms and hands above the surface may be exploited in useful ways, such as determining hover state, or that multiple touches are from same hand or from the same user. We present techniques and findings using Microsoft Kinect.},
author = {Wilson, Andrew D.},
booktitle = {Proc of ITS},
pages = {69--72},
title = {{Using a Depth Camera as a Touch Sensor}},
year = {2010}
}
@inproceedings{Harrison2010,
abstract = {We present Skinput, a technology that appropriates the human body for acoustic transmission, allowing the skin to be used as an input surface. In particular, we resolve the location of finger taps on the arm and hand by analyzing mechanical vibrations that propagate through the body. We collect these signals using a novel array of sensors worn as an armband. This approach provides an always available, naturally portable, and on-body finger input system. We assess the capabilities, accuracy and limitations of our technique through a two-part, twenty-participant user study. To further illustrate the utility of our approach, we conclude with several proof-of-concept applications we developed.},
author = {Harrison, Chris and Tan, Desney and Morris, Dan},
booktitle = {ACM SIGCHI},
doi = {10.1145/1753326.1753394},
isbn = {9781605589299},
issn = {21508097},
pages = {453--462},
title = {{Skinput: Appropriating the Body as an Input Surface}},
url = {http://portal.acm.org/citation.cfm?id=1753326.1753394\&amp;coll=GUIDE\&amp;dl=ACM\&amp;type=series\&amp;idx=SERIES260\&amp;part=series\&amp;WantType=Proceedings\&amp;title=CHI},
volume = {3},
year = {2010}
}
@inproceedings{Yang2012,
abstract = {We present Magic Finger, a small device worn on the fingertip, which supports always-available input. Magic Finger inverts the typical relationship between the finger and an interactive surface: with Magic Finger, we instrument the user's finger itself, rather than the surface it is touching. Magic Finger senses touch through an optical mouse sensor, enabling any surface to act as a touch screen. Magic Finger also senses texture through a micro RGB camera, allowing contextual actions to be carried out based on the particular surface being touched. A technical evaluation shows that Magic Finger can accurately sense 22 textures with an accuracy of 98.9\%. We explore the interaction design space enabled by Magic Finger, and implement a number of novel interaction techniques that leverage its unique capabilities.},
author = {Yang, Xing-Dong and Grossman, Tovi and Wigdor, Daniel and Fitzmaurice, George},
booktitle = {Proceedings of the 25th annual ACM symposium on User interface software and technology - UIST '12},
doi = {10.1145/2380116.2380137},
isbn = {9781450315807},
keywords = {always-available input,contextual action,gesture input,texture reorganization,touch input},
pages = {147--156},
title = {{Magic Finger: Always-Available Input through Finger Instrumentation}},
url = {http://dl.acm.org/citation.cfm?id=2380116.2380137},
year = {2012}
}
